{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import prettytable\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./Data/train.csv')\n",
    "test_df = pd.read_csv('./Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on june 27, 1962, phil st. amant, a candidate for public office, made a television speech in baton rouge, louisiana.  during this speech, st. amant accused his political opponent of being a communist and of being involved in criminal activities with the head of the local teamsters union.  finally, st. amant implicated herman thompson, an east baton rouge deputy sheriff, in a scheme to move money between the teamsters union and st. amant’s political opponent. \n",
      "thompson successfully sued st. amant for defamation.  louisiana’s first circuit court of appeals reversed, holding that thompson did not show st. amant acted with “malice.”  thompson then appealed to the supreme court of louisiana.  that court held that, although public figures forfeit some of their first amendment protection from defamation, st. amant accused thompson of a crime with utter disregard of whether the remarks were true.  finally, that court held that the first amendment protects uninhibited, robust debate, rather than an open season to shoot down the good name of anyone who happens to be a public servant. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df['first_party'] = train_df['first_party'].str.lower()\n",
    "train_df['second_party'] = train_df['second_party'].str.lower()\n",
    "train_df['facts'] = train_df['facts'].str.lower()\n",
    "\n",
    "test_df['first_party'] = test_df['first_party'].str.lower()\n",
    "test_df['second_party'] = test_df['second_party'].str.lower()\n",
    "test_df['facts'] = test_df['facts'].str.lower()\n",
    "\n",
    "idx = 0\n",
    "fact = train_df.loc[idx, 'facts'].lower()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(fact)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_re(name, fact_token: spacy.tokens.doc.Doc, first=True):\n",
    "    name = re.sub(rf'[ .,{string.punctuation}]+', r' ', name.lower())\n",
    "    name_list = [n for n in name.split() if len(n) >= 1]\n",
    "\n",
    "    for n in name_list:\n",
    "        changed_name = re.findall(rf\"{n} ?\\([a-z]+\\)\", fact_token.text)\n",
    "        # print(f\"changed name: {changed_name}\")\n",
    "        if changed_name:\n",
    "            name_list.extend([re.sub(rf'({n}|[ {string.punctuation}])', '', cn) for cn in changed_name])\n",
    "\n",
    "    # fact_subj = ' '.join([token.text for token in fact_token if 'NN' in token.tag_])\n",
    "    # print(f\"name list: {name_list}\")\n",
    "    # print(f\"fact subj: {fact_subj}\")\n",
    "    # res = []\n",
    "    # for name in name_list:\n",
    "    #     res.append((name, len(re.findall(name, fact_subj))))\n",
    "    # print(res)\n",
    "    abbrev = \"firstparty\" if first else \"secondparty\"\n",
    "    fact_subj = []\n",
    "    for token in fact_token:\n",
    "        if 'NN' in token.tag_ and token.text in name_list:\n",
    "            fact_subj.append(abbrev)\n",
    "        else:\n",
    "            fact_subj.append(token.text)\n",
    "    fact_subj = ' '.join(fact_subj)\n",
    "    # fact_subj = re.sub(rf\"({'|'.join(name_list)})\", abbrev, fact)\n",
    "    fact_subj = re.sub(rf\"({abbrev} ?)+\", f'{abbrev} ', fact_subj)\n",
    "    return fact_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_name(first_party, second_party, fact_token: spacy.tokens.doc.Doc):\n",
    "    first_party_name = re.sub(rf'[ .,{string.punctuation}]+', r' ', first_party.lower())\n",
    "    second_party_name = re.sub(rf'[ .,{string.punctuation}]+', r' ', second_party.lower())\n",
    "    fp_name_list = [n for n in first_party_name.split() if len(n) >= 1]\n",
    "    sp_name_list = [n for n in second_party_name.split() if len(n) >= 1]\n",
    "\n",
    "    fp_name_list_added = fp_name_list.copy()\n",
    "    sp_name_list_added = sp_name_list.copy()\n",
    "\n",
    "    for n in fp_name_list:\n",
    "        changed_name = re.findall(rf\"{n} ?\\([a-z]+\\)\", fact_token.text)\n",
    "        if changed_name:\n",
    "            fp_name_list_added.extend([re.sub(rf'({n}|[ {string.punctuation}])', '', cn) for cn in changed_name])\n",
    "    \n",
    "    for n in sp_name_list:\n",
    "        changed_name = re.findall(rf\"{n} ?\\([a-z]+\\)\", fact_token.text)\n",
    "        if changed_name:\n",
    "            sp_name_list_added.extend([re.sub(rf'({n}|[ {string.punctuation}])', '', cn) for cn in changed_name])\n",
    "\n",
    "    # for name_list in [fp_name_list, sp_name_list]:\n",
    "    #     for n in name_list:\n",
    "    #         changed_name = re.findall(rf\"{n} ?\\([a-z]+\\)\", fact_token.text)\n",
    "    #         if changed_name:\n",
    "    #             name_list.extend([re.sub(rf'({n}|[ {string.punctuation}])', '', cn) for cn in changed_name])\n",
    "    \n",
    "    # print(f\"fp name list: {fp_name_list}\")\n",
    "    # print(f\"sp name list: {sp_name_list}\")\n",
    "\n",
    "    fact_subj = []\n",
    "    for token in fact_token:\n",
    "        if 'NN' in token.tag_:\n",
    "            if token.text in fp_name_list_added:\n",
    "                fact_subj.append('firstparty')\n",
    "            elif token.text in sp_name_list_added:\n",
    "                fact_subj.append('secondparty')\n",
    "            else:\n",
    "                fact_subj.append(token.text)\n",
    "        else:\n",
    "            fact_subj.append(token.text)\n",
    "    \n",
    "    fact_subj = ' '.join(fact_subj)\n",
    "    fact_subj = re.sub(rf\"(firstparty ?)+\", f'firstparty ', fact_subj)\n",
    "    fact_subj = re.sub(rf\"(secondparty ?)+\", f'secondparty ', fact_subj)\n",
    "    return fact_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867d48d73adf4e5395dcafa2b0949f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1239), Label(value='0 / 1239'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9d6355253a4eb1a2c6deb4239d423a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=620), Label(value='0 / 620'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=2)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# train_df['facts_token'] = train_df['facts'].parallel_apply(nlp)\n",
    "train_df['new_facts'] = train_df.parallel_apply(lambda x: replace_name(x['first_party'], x['second_party'], nlp(x['facts'])), axis=1)\n",
    "test_df['new_facts'] = test_df.parallel_apply(lambda x: replace_name(x['first_party'], x['second_party'], nlp(x['facts'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename = {'first_party': 'fp',\n",
    "                 'second_party': 'sp',\n",
    "                 'first_party_winner': 'label'}\n",
    "\n",
    "train_df.rename(columns=column_rename, inplace=True)\n",
    "test_df.rename(columns=column_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fp</th>\n",
       "      <th>sp</th>\n",
       "      <th>facts</th>\n",
       "      <th>label</th>\n",
       "      <th>new_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>phil a. st. amant</td>\n",
       "      <td>herman a. thompson</td>\n",
       "      <td>on june 27, 1962, phil st. amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "      <td>on june 27 , 1962 , firstparty . firstparty , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>stephen duncan</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>billy joe magwood</td>\n",
       "      <td>tony patterson, warden, et al.</td>\n",
       "      <td>an alabama state court convicted billy joe mag...</td>\n",
       "      <td>1</td>\n",
       "      <td>an alabama state court convicted billy firstpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>linkletter</td>\n",
       "      <td>walker</td>\n",
       "      <td>victor linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "      <td>victor firstparty was convicted in state court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>on april 24, 1953 in selma, alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "      <td>on april 24 , 1953 in selma , secondparty , an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>TRAIN_2473</td>\n",
       "      <td>hollyfrontier cheyenne refining, llc, et al.</td>\n",
       "      <td>renewable fuels association, et al.</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "      <td>1</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>TRAIN_2474</td>\n",
       "      <td>grupo mexicano de desarrollo, s. a.</td>\n",
       "      <td>alliance bond fund, inc.</td>\n",
       "      <td>alliance bond fund, inc., an investment fund, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>secondparty , secondparty . , an investment se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>TRAIN_2475</td>\n",
       "      <td>peguero</td>\n",
       "      <td>united states</td>\n",
       "      <td>in 1992, the district court sentenced manuel d...</td>\n",
       "      <td>0</td>\n",
       "      <td>in 1992 , the district court sentenced manuel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>TRAIN_2476</td>\n",
       "      <td>immigration and naturalization service</td>\n",
       "      <td>st. cyr</td>\n",
       "      <td>on march 8, 1996, enrico st. cyr, a lawful per...</td>\n",
       "      <td>0</td>\n",
       "      <td>on march 8 , 1996 , enrico secondparty . secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>markman</td>\n",
       "      <td>westview instruments, inc.</td>\n",
       "      <td>herbert markman owns the patent to a system th...</td>\n",
       "      <td>0</td>\n",
       "      <td>herbert firstparty owns the patent to a system...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                            fp   \n",
       "0     TRAIN_0000                             phil a. st. amant  \\\n",
       "1     TRAIN_0001                                stephen duncan   \n",
       "2     TRAIN_0002                             billy joe magwood   \n",
       "3     TRAIN_0003                                    linkletter   \n",
       "4     TRAIN_0004                            william earl fikes   \n",
       "...          ...                                           ...   \n",
       "2473  TRAIN_2473  hollyfrontier cheyenne refining, llc, et al.   \n",
       "2474  TRAIN_2474           grupo mexicano de desarrollo, s. a.   \n",
       "2475  TRAIN_2475                                       peguero   \n",
       "2476  TRAIN_2476        immigration and naturalization service   \n",
       "2477  TRAIN_2477                                       markman   \n",
       "\n",
       "                                       sp   \n",
       "0                      herman a. thompson  \\\n",
       "1                          lawrence owens   \n",
       "2          tony patterson, warden, et al.   \n",
       "3                                  walker   \n",
       "4                                 alabama   \n",
       "...                                   ...   \n",
       "2473  renewable fuels association, et al.   \n",
       "2474             alliance bond fund, inc.   \n",
       "2475                        united states   \n",
       "2476                              st. cyr   \n",
       "2477           westview instruments, inc.   \n",
       "\n",
       "                                                  facts  label   \n",
       "0     on june 27, 1962, phil st. amant, a candidate ...      1  \\\n",
       "1     ramon nelson was riding his bike when he suffe...      0   \n",
       "2     an alabama state court convicted billy joe mag...      1   \n",
       "3     victor linkletter was convicted in state court...      0   \n",
       "4     on april 24, 1953 in selma, alabama, an intrud...      1   \n",
       "...                                                 ...    ...   \n",
       "2473  congress amended the clean air act through the...      1   \n",
       "2474  alliance bond fund, inc., an investment fund, ...      1   \n",
       "2475  in 1992, the district court sentenced manuel d...      0   \n",
       "2476  on march 8, 1996, enrico st. cyr, a lawful per...      0   \n",
       "2477  herbert markman owns the patent to a system th...      0   \n",
       "\n",
       "                                              new_facts  \n",
       "0     on june 27 , 1962 , firstparty . firstparty , ...  \n",
       "1     ramon nelson was riding his bike when he suffe...  \n",
       "2     an alabama state court convicted billy firstpa...  \n",
       "3     victor firstparty was convicted in state court...  \n",
       "4     on april 24 , 1953 in selma , secondparty , an...  \n",
       "...                                                 ...  \n",
       "2473  congress amended the clean air act through the...  \n",
       "2474  secondparty , secondparty . , an investment se...  \n",
       "2475  in 1992 , the district court sentenced manuel ...  \n",
       "2476  on march 8 , 1996 , enrico secondparty . secon...  \n",
       "2477  herbert firstparty owns the patent to a system...  \n",
       "\n",
       "[2478 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1649\n",
       "0     829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fp</th>\n",
       "      <th>sp</th>\n",
       "      <th>facts</th>\n",
       "      <th>new_facts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>herman a. thompson</td>\n",
       "      <td>phil a. st. amant</td>\n",
       "      <td>on june 27, 1962, phil st. amant, a candidate ...</td>\n",
       "      <td>on june 27 , 1962 , firstparty . firstparty , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>stephen duncan</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>tony patterson, warden, et al.</td>\n",
       "      <td>billy joe magwood</td>\n",
       "      <td>an alabama state court convicted billy joe mag...</td>\n",
       "      <td>an alabama state court convicted billy firstpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>walker</td>\n",
       "      <td>linkletter</td>\n",
       "      <td>victor linkletter was convicted in state court...</td>\n",
       "      <td>victor firstparty was convicted in state court...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>alabama</td>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>on april 24, 1953 in selma, alabama, an intrud...</td>\n",
       "      <td>on april 24 , 1953 in selma , secondparty , an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>TRAIN_2473</td>\n",
       "      <td>renewable fuels association, et al.</td>\n",
       "      <td>hollyfrontier cheyenne refining, llc, et al.</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>TRAIN_2474</td>\n",
       "      <td>alliance bond fund, inc.</td>\n",
       "      <td>grupo mexicano de desarrollo, s. a.</td>\n",
       "      <td>alliance bond fund, inc., an investment fund, ...</td>\n",
       "      <td>secondparty , secondparty . , an investment se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>TRAIN_2475</td>\n",
       "      <td>united states</td>\n",
       "      <td>peguero</td>\n",
       "      <td>in 1992, the district court sentenced manuel d...</td>\n",
       "      <td>in 1992 , the district court sentenced manuel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>TRAIN_2476</td>\n",
       "      <td>st. cyr</td>\n",
       "      <td>immigration and naturalization service</td>\n",
       "      <td>on march 8, 1996, enrico st. cyr, a lawful per...</td>\n",
       "      <td>on march 8 , 1996 , enrico secondparty . secon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>westview instruments, inc.</td>\n",
       "      <td>markman</td>\n",
       "      <td>herbert markman owns the patent to a system th...</td>\n",
       "      <td>herbert firstparty owns the patent to a system...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                   fp   \n",
       "0     TRAIN_0000                   herman a. thompson  \\\n",
       "1     TRAIN_0001                       lawrence owens   \n",
       "2     TRAIN_0002       tony patterson, warden, et al.   \n",
       "3     TRAIN_0003                               walker   \n",
       "4     TRAIN_0004                              alabama   \n",
       "...          ...                                  ...   \n",
       "2473  TRAIN_2473  renewable fuels association, et al.   \n",
       "2474  TRAIN_2474             alliance bond fund, inc.   \n",
       "2475  TRAIN_2475                        united states   \n",
       "2476  TRAIN_2476                              st. cyr   \n",
       "2477  TRAIN_2477           westview instruments, inc.   \n",
       "\n",
       "                                                sp   \n",
       "0                                phil a. st. amant  \\\n",
       "1                                   stephen duncan   \n",
       "2                                billy joe magwood   \n",
       "3                                       linkletter   \n",
       "4                               william earl fikes   \n",
       "...                                            ...   \n",
       "2473  hollyfrontier cheyenne refining, llc, et al.   \n",
       "2474           grupo mexicano de desarrollo, s. a.   \n",
       "2475                                       peguero   \n",
       "2476        immigration and naturalization service   \n",
       "2477                                       markman   \n",
       "\n",
       "                                                  facts   \n",
       "0     on june 27, 1962, phil st. amant, a candidate ...  \\\n",
       "1     ramon nelson was riding his bike when he suffe...   \n",
       "2     an alabama state court convicted billy joe mag...   \n",
       "3     victor linkletter was convicted in state court...   \n",
       "4     on april 24, 1953 in selma, alabama, an intrud...   \n",
       "...                                                 ...   \n",
       "2473  congress amended the clean air act through the...   \n",
       "2474  alliance bond fund, inc., an investment fund, ...   \n",
       "2475  in 1992, the district court sentenced manuel d...   \n",
       "2476  on march 8, 1996, enrico st. cyr, a lawful per...   \n",
       "2477  herbert markman owns the patent to a system th...   \n",
       "\n",
       "                                              new_facts  label  \n",
       "0     on june 27 , 1962 , firstparty . firstparty , ...      0  \n",
       "1     ramon nelson was riding his bike when he suffe...      1  \n",
       "2     an alabama state court convicted billy firstpa...      0  \n",
       "3     victor firstparty was convicted in state court...      1  \n",
       "4     on april 24 , 1953 in selma , secondparty , an...      0  \n",
       "...                                                 ...    ...  \n",
       "2473  congress amended the clean air act through the...      0  \n",
       "2474  secondparty , secondparty . , an investment se...      0  \n",
       "2475  in 1992 , the district court sentenced manuel ...      1  \n",
       "2476  on march 8 , 1996 , enrico secondparty . secon...      1  \n",
       "2477  herbert firstparty owns the patent to a system...      1  \n",
       "\n",
       "[2478 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df = pd.DataFrame({'ID': train_df['ID'],\n",
    "                       'fp': train_df['sp'],\n",
    "                       'sp': train_df['fp'],\n",
    "                       'facts': train_df['facts'],\n",
    "                       'new_facts': train_df['new_facts'],\n",
    "                       'label': 1-train_df['label']})\n",
    "\n",
    "aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fp</th>\n",
       "      <th>sp</th>\n",
       "      <th>facts</th>\n",
       "      <th>label</th>\n",
       "      <th>new_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>phil a. st. amant</td>\n",
       "      <td>herman a. thompson</td>\n",
       "      <td>on june 27, 1962, phil st. amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "      <td>on june 27 , 1962 , firstparty . firstparty , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>stephen duncan</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "      <td>ramon nelson was riding his bike when he suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>billy joe magwood</td>\n",
       "      <td>tony patterson, warden, et al.</td>\n",
       "      <td>an alabama state court convicted billy joe mag...</td>\n",
       "      <td>1</td>\n",
       "      <td>an alabama state court convicted billy firstpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>linkletter</td>\n",
       "      <td>walker</td>\n",
       "      <td>victor linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "      <td>victor firstparty was convicted in state court...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>on april 24, 1953 in selma, alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "      <td>on april 24 , 1953 in selma , secondparty , an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>TRAIN_2473</td>\n",
       "      <td>renewable fuels association, et al.</td>\n",
       "      <td>hollyfrontier cheyenne refining, llc, et al.</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "      <td>0</td>\n",
       "      <td>congress amended the clean air act through the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>TRAIN_2474</td>\n",
       "      <td>alliance bond fund, inc.</td>\n",
       "      <td>grupo mexicano de desarrollo, s. a.</td>\n",
       "      <td>alliance bond fund, inc., an investment fund, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>secondparty , secondparty . , an investment se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>TRAIN_2475</td>\n",
       "      <td>united states</td>\n",
       "      <td>peguero</td>\n",
       "      <td>in 1992, the district court sentenced manuel d...</td>\n",
       "      <td>1</td>\n",
       "      <td>in 1992 , the district court sentenced manuel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>TRAIN_2476</td>\n",
       "      <td>st. cyr</td>\n",
       "      <td>immigration and naturalization service</td>\n",
       "      <td>on march 8, 1996, enrico st. cyr, a lawful per...</td>\n",
       "      <td>1</td>\n",
       "      <td>on march 8 , 1996 , enrico secondparty . secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>westview instruments, inc.</td>\n",
       "      <td>markman</td>\n",
       "      <td>herbert markman owns the patent to a system th...</td>\n",
       "      <td>1</td>\n",
       "      <td>herbert firstparty owns the patent to a system...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4956 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                   fp   \n",
       "0     TRAIN_0000                    phil a. st. amant  \\\n",
       "1     TRAIN_0001                       stephen duncan   \n",
       "2     TRAIN_0002                    billy joe magwood   \n",
       "3     TRAIN_0003                           linkletter   \n",
       "4     TRAIN_0004                   william earl fikes   \n",
       "...          ...                                  ...   \n",
       "4951  TRAIN_2473  renewable fuels association, et al.   \n",
       "4952  TRAIN_2474             alliance bond fund, inc.   \n",
       "4953  TRAIN_2475                        united states   \n",
       "4954  TRAIN_2476                              st. cyr   \n",
       "4955  TRAIN_2477           westview instruments, inc.   \n",
       "\n",
       "                                                sp   \n",
       "0                               herman a. thompson  \\\n",
       "1                                   lawrence owens   \n",
       "2                   tony patterson, warden, et al.   \n",
       "3                                           walker   \n",
       "4                                          alabama   \n",
       "...                                            ...   \n",
       "4951  hollyfrontier cheyenne refining, llc, et al.   \n",
       "4952           grupo mexicano de desarrollo, s. a.   \n",
       "4953                                       peguero   \n",
       "4954        immigration and naturalization service   \n",
       "4955                                       markman   \n",
       "\n",
       "                                                  facts  label   \n",
       "0     on june 27, 1962, phil st. amant, a candidate ...      1  \\\n",
       "1     ramon nelson was riding his bike when he suffe...      0   \n",
       "2     an alabama state court convicted billy joe mag...      1   \n",
       "3     victor linkletter was convicted in state court...      0   \n",
       "4     on april 24, 1953 in selma, alabama, an intrud...      1   \n",
       "...                                                 ...    ...   \n",
       "4951  congress amended the clean air act through the...      0   \n",
       "4952  alliance bond fund, inc., an investment fund, ...      0   \n",
       "4953  in 1992, the district court sentenced manuel d...      1   \n",
       "4954  on march 8, 1996, enrico st. cyr, a lawful per...      1   \n",
       "4955  herbert markman owns the patent to a system th...      1   \n",
       "\n",
       "                                              new_facts  \n",
       "0     on june 27 , 1962 , firstparty . firstparty , ...  \n",
       "1     ramon nelson was riding his bike when he suffe...  \n",
       "2     an alabama state court convicted billy firstpa...  \n",
       "3     victor firstparty was convicted in state court...  \n",
       "4     on april 24 , 1953 in selma , secondparty , an...  \n",
       "...                                                 ...  \n",
       "4951  congress amended the clean air act through the...  \n",
       "4952  secondparty , secondparty . , an investment se...  \n",
       "4953  in 1992 , the district court sentenced manuel ...  \n",
       "4954  on march 8 , 1996 , enrico secondparty . secon...  \n",
       "4955  herbert firstparty owns the patent to a system...  \n",
       "\n",
       "[4956 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, aug_df], ignore_index=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2478\n",
       "0    2478\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': Value(dtype='string', id=None),\n",
       " 'fp': Value(dtype='string', id=None),\n",
       " 'sp': Value(dtype='string', id=None),\n",
       " 'facts': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'new_facts': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403c72897a5f4a75b58d6aa0f1000135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/4956 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a5d8fee8db48218bbd5c9ee1aacf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4956 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "label = datasets.ClassLabel(num_classes=2, names=[0, 1])\n",
    "train_data.features['label'] = label\n",
    "train_data = train_data.class_encode_column(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'fp', 'sp', 'facts', 'label', 'new_facts'],\n",
       "    num_rows: 4956\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'fp', 'sp', 'facts', 'label', 'new_facts'],\n",
       "        num_rows: 3964\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'fp', 'sp', 'facts', 'label', 'new_facts'],\n",
       "        num_rows: 992\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'fp', 'sp', 'facts', 'new_facts'],\n",
       "        num_rows: 1240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.train_test_split(test_size=0.2, shuffle=True, seed=42, stratify_by_column='label')\n",
    "dataset = DatasetDict({'train': train_data['train'], 'validation': train_data['test'], 'test': test_data})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(train_data['train']['label']), np.mean(train_data['test']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"distilbert-base-uncased\"\n",
    "# pretrained_model = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a2b1e0448c4fe38e9beba06556fa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753026d084dc4cbc8c8d56c7dc05d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1159354b762d4569bbd76bc0c99d0458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    examples['facts_with_party'] = [f'First: {first}.\\n Second: {second}.\\nFacts: {new_fact}' \n",
    "                                    for first, second, new_fact in zip(examples['fp'], examples['sp'], examples['new_facts'])]\n",
    "    return tokenizer(examples['facts_with_party'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2480' max='2480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2480/2480 12:36, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696901</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693649</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693897</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693715</td>\n",
       "      <td>0.497984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.694052</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.694866</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.696856</td>\n",
       "      <td>0.486895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.699583</td>\n",
       "      <td>0.478831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.706079</td>\n",
       "      <td>0.462702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.732473</td>\n",
       "      <td>0.431452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.733508</td>\n",
       "      <td>0.424395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.424395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.840522</td>\n",
       "      <td>0.423387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.874551</td>\n",
       "      <td>0.398185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.950608</td>\n",
       "      <td>0.403226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.397177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>1.062137</td>\n",
       "      <td>0.394153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>1.079410</td>\n",
       "      <td>0.398185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>1.102461</td>\n",
       "      <td>0.405242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/yunho/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2480, training_loss=0.646895500921434, metrics={'train_runtime': 757.9879, 'train_samples_per_second': 104.593, 'train_steps_per_second': 3.272, 'total_flos': 1.050201536544768e+16, 'train_loss': 0.646895500921434, 'epoch': 20.0})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, PreTrainedTokenizerBase\n",
    "import torch\n",
    "\n",
    "class CustomDataCollatorForLanguageModeling(DataCollatorForLanguageModeling):\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        mlm_probability=0.15, \n",
    "        pad_to_multiple_of=None,\n",
    "        special_tokens_to_mask=[\"firstparty\", \"secondparty\", \"court\"]\n",
    "    ):\n",
    "        super().__init__(tokenizer=tokenizer, mlm=mlm_probability, pad_to_multiple_of=pad_to_multiple_of)\n",
    "        self.special_tokens_to_mask = [self.tokenizer.encode(st, add_special_tokens=False)[0] for st in special_tokens_to_mask]\n",
    "\n",
    "    def mask_tokens(self, inputs: torch.Tensor):\n",
    "        labels = inputs.clone()\n",
    "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
    "        \n",
    "        for special_token in self.special_tokens_to_mask:\n",
    "            special_token_mask = labels.eq(special_token)\n",
    "            probability_matrix.masked_fill_(special_token_mask, 1.0)\n",
    "        \n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "        return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondparty observed oil producer - operated stations receiving favorable rates from producers and refiners . in response , secondparty passed a statute prohibiting oil producers or refiners from operating gasoline stations within the state and requiring producers and refiners extend temporary price cuts to the stations they supplied . firstparty challenged the statute in anne arundel county circuit court , which ruled the statute invalid . the secondparty court of appeals reversed the ruling . \n",
      "\n",
      "[MASK] [MASK]party observed oil [MASK] - operated stations receiving [MASK] rates [MASK] producers and refiner [MASK]. in response, [MASK]party passed a statute prohibiting oil producers or refiners from operating [MASK] stations within the state and requiring producers and refiners extend temporary price cuts [MASK] the stations they supplied [MASK] [MASK]party challenged the statute [MASK] anne arundel county circuit [MASK], which ruled the statute [MASK]. the [MASK]par [MASK] cinema of appeals reversed the ruling. [SEP]\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollatorForLanguageModeling(tokenizer)\n",
    "\n",
    "sentence = train_data['train']['new_facts'][0]\n",
    "\n",
    "inputs = tokenizer.encode(sentence, return_tensors='pt')\n",
    "masked_inputs, labels = data_collator.mask_tokens(inputs)\n",
    "masked_sentence = tokenizer.decode(masked_inputs[0])\n",
    "print(sentence)\n",
    "print(masked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def mask_text(text, words_to_mask):\n",
    "    MASK_TOKEN = '[MASK]'\n",
    "    for word in words_to_mask:\n",
    "        text = re.sub(word, MASK_TOKEN, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
