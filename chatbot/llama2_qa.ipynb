{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T07:29:17.955811247Z",
     "start_time": "2023-08-03T07:29:15.464722422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/yunho/.cache/huggingface/datasets/json/default-7673f6a0c673c641/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "basic_dataset = load_dataset(\"json\", data_files=\"./Data/wholeqa.jsonl\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 12664\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 1408\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "split_dataset = basic_dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset = split_dataset['train']\n",
    "valid_dataset = split_dataset['test']\n",
    "\n",
    "wholeqa_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': valid_dataset\n",
    "})\n",
    "\n",
    "print(wholeqa_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T07:29:22.019900462Z",
     "start_time": "2023-08-03T07:29:21.984923357Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_text = \"\"\"다음과 같은 법률 상담 질문이 있다.\n",
    "\n",
    "{}\n",
    "\n",
    "이 사건에 대한 법률 상담 답변은 다음과 같다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wholeqa_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T07:29:22.020189507Z",
     "start_time": "2023-08-03T07:29:21.985321395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음과 같은 법률 상담 질문이 있다.\n",
      "\n",
      "이행지체 중의 양도소득세 부과분에 대한 매수인의 책임여부: 甲은 A토지에 관하여 乙과 매매계약을 체결하였는데, 乙은 甲과 약정한 잔금 지급기일에 잔금을 지급하지 않았습니다(하지만 甲은 乙의 잔금지급 지체를 이유로 매매계약을 해제하지는 않았습니다). 그런데 乙이 잔금지급을 지체하고 있는 사이에 A토지의 개별공시지가는 급등하였고, 이로 인하여 甲은 추가로 양도소득세를 부담하게 되었습니다. 이에 甲은 乙로부터 乙의 잔금지급 지체로 인하여 추가로 부담하게 된 양도소득세의 차액부분을 지급받을 수 있는지요?\n",
      "\n",
      "이 사건에 대한 법률 상담 답변은 다음과 같다.\n",
      "\n",
      "\n",
      "(1)「민법」은 채무불이행으로 인한 손해배상은 통상의 손해를 그 한도로 하고, 특별한 사정으로 인한 손해는 채무자가 그 사정을 알았거나 알 수 있었을 때에 한하여 배상의 책임이 있다고 규정하고 있습니다(같은 법 제393조).\n",
      "  (2) 통상손해란 채무불이행이 있으면 일반적으로 발생하는 것으로 여겨지는 손해를 말하고, 특별손해란 채무불이행으로 인해 일반적으로 발생하는 손해가 아닌 채권자에게 존재하는 특별한 사정에 기초하여 발생하는 손해를 뜻합니다. 따라서 채무자는 채무불이행으로 인하여 채권자가 입게 된 통상손해에 대해서는 그 전부에 대하여 배상책임을 부담하게 되지만, 특별손해에 대해서는 채권자에게 존재하는 특별한 사정에 관하여 채무자가 ‘알았거나 알 수 있었을 때’에 한하여 예외적으로 배상책임을 부담하게 됩니다.\n",
      "  (3) 위 사안에서 판례는 “매수인의 잔금지급 지체로 인하여 계약을 해제하지 아니한 매도인이 지체된 기간 동안 입은 손해 중 그 미지급 잔금에 대한 법정이율에 따른 이자 상당의 금액은 통상손해라고 할 것이지만, 그 사이에 매매대상 토지의 개별공시지가가 급등하여 매도인의 양도소득세 부담이 늘었다고 하더라도 그 손해는 사회일반의 관념상 매매계약에서의 잔금지급의 이행지체의 경우 통상 발생하는 것으로 생각되는 범위의 통상손해라고 할 수는 없고, 이는 특별한 사정에 의하여 발생한 손해에 해당한다고 할 것이다.”라고 하였습니다(대법원 2006. 4. 13. 선고 2005다75897 판결).\n",
      "  (4) 따라서 甲은 乙로부터 乙의 지체기간 동안의 미지급 잔금에 대한 법정이율에 따른 이자 상당의 금액을 통상손해로서 배상받을 수 있을 것으로 보이나, 乙의 잔금지급 지체로 인하여 추가로 부담하게 된 양도소득세 차액부분을 배상받기 위해서는 乙이 A토지의 개별공시지가의 급등이라는 특별한 사정을 알았거나 알 수 있었다는 사실을 입증하여야만 할 것입니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.random.randint(0, len(wholeqa_dataset['train']))\n",
    "\n",
    "question = wholeqa_dataset['train'][idx]['instruction']\n",
    "answer = wholeqa_dataset['train'][idx]['output']\n",
    "\n",
    "print(qa_text.format(question))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T07:29:23.200819643Z",
     "start_time": "2023-08-03T07:29:21.985716163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5487e9c905484925b555a65651b510a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c22c4ad10a48628813bddc589018de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_dataset = wholeqa_dataset.map(lambda x: {\n",
    "    'text': qa_text.format(x['instruction'], x['output'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T07:29:24.506186587Z",
     "start_time": "2023-08-03T07:29:24.456896489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 12664\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text'],\n",
       "        num_rows: 1408\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_ckpt = \"beomi/llama-2-ko-7b\"\n",
    "# model_ckpt = \"kfkas/Llama-2-ko-7b-Chat\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bits=True, # 8bit quantization\n",
    "    bnb_8bit_use_double_quant=True, # 양자화 상수 중복 계산\n",
    "    bnb_8bit_quant_type=\"nf4\",\n",
    "    bnb_8bit_compute_dtype=th.bfloat16 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> 2\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, padding_side='right')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(tokenizer.eos_token, tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f2f12a474c40d7b772d47449a6d927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_ckpt, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cdda0ba0dc48e5931bb96704729195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd3d9a4672a4ab9b3f449796f5dbc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode(examples):\n",
    "    inputs = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "    labels = tokenizer(examples['output'], truncation=True, padding='max_length', max_length=512)\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "qa_dataset = qa_dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12664\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1408\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 08:16:19.999672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 08:16:20.111766: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 08:16:20.618732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/mesa-diverted/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/mesa:/usr/lib/x86_64-linux-gnu/dri:/usr/lib/x86_64-linux-gnu/gallium-pipe:/usr/local/cuda-11.8/lib64\n",
      "2023-08-31 08:16:20.618785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/mesa-diverted/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/mesa:/usr/lib/x86_64-linux-gnu/dri:/usr/lib/x86_64-linux-gnu/gallium-pipe:/usr/local/cuda-11.8/lib64\n",
      "2023-08-31 08:16:20.618790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 다음과 같은 법률 상담 질문이 있다.\n",
      "\n",
      "甲은 근로복지공단으로부터 폐질 3급 4호에 해당한다는 이유로 상병보상연금을 지급받고 있었습니다. 그런데, A의 불법행위로 인해 甲이 사망하는 사고가 발생하였습니다.A의 손해배상금을 산정함에 있어 甲이 상병보상연금을 지급받고 있었다는 사실이 일실수익의 산정 또는 과실상계에 반영될 여지가 있는지요?\n",
      "\n",
      "이 사건에 대한 법률 상담 답변은 다음과 같다.\n",
      "\n",
      "</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "====================================================================================================\n",
      "<s> 상병보상연금은 요양급여를 받는 근로자가 요양을 시작하지 2년이 지난 날 이후에도 그 부상이나 질병이 치유되지 않고, 요양으로 인해 취업하지 못하는 상태가 계속되는 경우에, 그 부상이나 질병에 따른 폐질의 정도에 따라 일정한 일수분의 평균임금을 지급하는 것입니다. 이는 산업재해보상보험법에 따라 보험사고에 해당하는 일정한 사유가 발생했을 경우 지급되는 사회보험급여의 일종인데, 일실수입은 일반적으로 사고 당시에 종사하고 있었던 직업이나 업무로부터 얻고 있는 소득액을 일차적인 기준으로 하여 산정될 뿐만 아니라, 위 상병보상연금은 피해자의 특수한 사정으로 인해 지급받는 보험급여로써 이를 받지 못하게 되는 손해는 민법상 특별손해여서 가해자가 이 사실을 알았거나 알 수 있었던 경우에만 배상을 청구할 수 있을 것으로도 판단되는바, 결국 A의 독립된 불법행위로 인해 피해자인 甲이 사망하였을 때에 그가 생전에 지급받고 있었던 상병보상연금을 일실수입 산정의 기초로 삼기는 다소 어려워 보입니다. 다만, 이는 개인적인 견해이며, 해당 사안에 관한 명시적인 판례는 존재하지 않는 것으로 보입니다. 한편, 상병보상연금을 지급받고 있었다는 것은 부상이나 질병으로 인한 폐질의 상태에 있었음을 의미하는바, 甲의 그러한 신체적, 기질적 장해가 A의 불법행위와 경합적으로 사망이라는 결과 발생의 원인이 되었다고 볼 수 있는 경우에는, A의 손해배상액을 산정함에 있어 甲이 본래 가지고 있던 신체적, 기질적 장해가 결과 발생에 기여한 정도를 참작하여야 할 것입니다. 원칙적으로 과실상계라 함은 불법행위로 인한 손해의 발생 또는 확대에 피해자가 유책적으로 공동한 경우, 이를 손해배상책임의 유무 또는 그 범위를 결정함에 있어 참작하는 것을 의미합니다(민법 제763조, 제396조). 그런데, 우리 판례는 피해자측의 귀책사유와 무관하게 본래 가지고 있던 피해자의 체질적 소인 또는 질병의 위험도 등 피해자측의 요인이 가해행위와 경합하여 손해가 발생, 확대된 경우에도 공평의 이념에 비추어 손해배상액을 정하면서 과실상계의 법리를 '유추적용'하여 위 피해자측의 요인을 참작할 수 있다는 태도입니다(가령, 대법원 2000. 1.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(qa_dataset['train']['input_ids'][0]))\n",
    "print('=' * 100)\n",
    "print(tokenizer.decode(qa_dataset['train']['labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,860,050,432 || trainable%: 0.06114100824149743\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8, # attention dim\n",
    "    lora_alpha=32, # LoRA 스케일링 파라미터\n",
    "    target_modules=[\"q_proj\", \"v_proj\"], # LoRA 적용할 모듈\n",
    "    # target_modules=[\"query_key_value\"] : 오류 발생(이유 모름)\n",
    "    lora_dropout=0.05, # LoRA 드롭아웃\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_config.inference_mode = False\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', th.cuda.current_device())\n",
    "print('Count of using GPUs:', th.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12664\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1408\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_steps=200,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-4,\n",
    "    # max_grad_norm=2.0,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    logging_strategy='steps',\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    report_to = 'tensorboard'\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=qa_dataset['train'],\n",
    "    eval_dataset=qa_dataset['validation'],\n",
    "    args=args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 51/792 10:50 < 2:43:58, 0.08 it/s, Epoch 0.13/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/home/yunho/legal_basic/llama2_legal_basic\")\n",
    "tokenizer.save_pretrained(\"/home/yunho/legal_basic/llama2_legal_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
